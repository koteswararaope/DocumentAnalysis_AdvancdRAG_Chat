{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840b4da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2d6e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658a47c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767e6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ChatGroq(model = \"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6a7a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking \"where is New Delhi?\" I need to provide a clear and concise answer. Let me start by recalling that New Delhi is the capital of India. I should mention its location within India, maybe specify the state it\\'s in, which is Delhi. Wait, but Delhi is actually a union territory, right? So I should clarify that. \\n\\nNext, for someone who might not know much about India\\'s geography, it might help to mention neighboring countries or major cities. For example, it\\'s near the border with Pakistan, but not too close. Maybe mention states around it, like Haryana and Uttar Pradesh. Also, its position in northern India.\\n\\nI should include some geographical coordinates to be precise. Let me check the approximate latitude and longitude. I think it\\'s around 28.6139째 N, 77.2090째 E. That\\'s correct. Also, the altitude is about 217 meters above sea level.\\n\\nWhat else? New Delhi is part of the National Capital Territory of Delhi. Maybe explain that it\\'s a planned city, designed by architects like Edwin Lutyens and Herbert Baker. The city has a mix of traditional and modern architecture. It\\'s known for historical landmarks like the Red Fort, Qutub Minar, and the India Gate. Also, it\\'s a political and cultural hub.\\n\\nI should also note the population, maybe around 28 million in the metropolitan area. That\\'s a significant number. Transportation-wise, it has a metro system, airports like Indira Gandhi International Airport.\\n\\nWait, the user might be asking for directions or how to get there, but the question is just about the location. So focus on geographical and administrative aspects. Also, mention that it\\'s distinct from Old Delhi, which is the older part of the city.\\n\\nDouble-check if there\\'s any common confusion between New Delhi and Delhi. Sometimes people refer to the entire city as Delhi, but technically, New Delhi is a district within the National Capital Territory of Delhi. Clarify that if necessary.\\n\\nMake sure the answer is accurate, concise, and covers the key points: country, region, nearby areas, geographical coordinates, status as a capital, and maybe some key landmarks. Avoid any unnecessary jargon but provide enough detail for clarity.\\n</think>\\n\\n**New Delhi** is the **capital of India** and serves as the political and administrative center of the country. Here\\'s a detailed overview of its location and key features:\\n\\n1. **Geographical Location**:  \\n   - Located in the **National Capital Territory of Delhi**, which is a **union territory** of India.  \\n   - Situated in **northern India**, near the border with **Pakistan**.  \\n   - Surrounded by the states of **Haryana** (to the west, north, and east) and **Uttar Pradesh** (to the east).  \\n\\n2. **Coordinates**:  \\n   - Latitude: **28.6139째 N**  \\n   - Longitude: **77.2090째 E**  \\n   - Elevation: Approximately **217 meters (712 feet)** above sea level.  \\n\\n3. **Administrative Context**:  \\n   - New Delhi is a **planned city** designed by British architects **Edwin Lutyens** and **Herbert Baker** during the early 20th century.  \\n   - It is distinct from **Old Delhi**, the historic Mughal-era city, which lies a few kilometers to the north.  \\n\\n4. **Key Features**:  \\n   - **Political Hub**: Home to government institutions like the **Rashtrapati Bhavan** (President\\'s House), **Parliament House**, and **Lok Kala Museum**.  \\n   - **Cultural and Historical Sites**: Includes landmarks such as the **Red Fort**, **Qutub Minar**, **India Gate**, and **Humayun\\'s Tomb**.  \\n   - **Transportation**: Served by **Indira Gandhi International Airport** and a modern **metro system**.  \\n\\n5. **Demographics**:  \\n   - The **Delhi Metropolitan Area** has a population of over **28 million**, making it one of the world\\'s most populous urban regions.  \\n\\nIn summary, New Delhi is a vibrant, historically significant city at the heart of India\\'s governance and culture, strategically located in northern India.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 905, 'prompt_tokens': 14, 'total_tokens': 919, 'completion_time': 3.7643531059999997, 'prompt_time': 0.007079953, 'queue_time': 0.210146067, 'total_time': 3.771433059}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5b40072-e730-4e74-93e7-2a137fd38d86-0', usage_metadata={'input_tokens': 14, 'output_tokens': 905, 'total_tokens': 919})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"where is new delhi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef82557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c4a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdedding_model = GoogleGenerativeAIEmbeddings(model =\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80bbcfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04433692991733551,\n",
       " 0.00699573801830411,\n",
       " -0.06549712270498276,\n",
       " -0.01715826615691185,\n",
       " 0.048965390771627426,\n",
       " 0.02333848364651203,\n",
       " 0.031678300350904465,\n",
       " -0.006987929809838533,\n",
       " 0.010462739504873753,\n",
       " 0.062008630484342575,\n",
       " -0.03259121999144554,\n",
       " 0.020617589354515076,\n",
       " -0.016330992802977562,\n",
       " 0.019450459629297256,\n",
       " 0.0037003301549702883,\n",
       " -0.01399842556566,\n",
       " 0.01470889337360859,\n",
       " 0.006311079952865839,\n",
       " 0.029109245166182518,\n",
       " 0.00046806002501398325,\n",
       " 0.024623390287160873,\n",
       " -0.012324889190495014,\n",
       " -0.01583213172852993,\n",
       " 0.01895468682050705,\n",
       " 0.025217445567250252,\n",
       " -0.01996988244354725,\n",
       " -0.005269229877740145,\n",
       " -0.055423278361558914,\n",
       " -0.018035918474197388,\n",
       " -0.013850034214556217,\n",
       " -0.04238704964518547,\n",
       " 0.04118114709854126,\n",
       " -0.03464901074767113,\n",
       " 0.0316159650683403,\n",
       " 0.023362930864095688,\n",
       " -0.05730219557881355,\n",
       " -0.02638065069913864,\n",
       " 0.04128924012184143,\n",
       " -0.036266107112169266,\n",
       " 0.03631479665637016,\n",
       " 0.003299003466963768,\n",
       " -0.021644271910190582,\n",
       " -0.08695508539676666,\n",
       " 0.017317313700914383,\n",
       " 0.004218320362269878,\n",
       " 0.01813051849603653,\n",
       " -0.07344352453947067,\n",
       " 0.023398760706186295,\n",
       " 0.021001262590289116,\n",
       " -0.03174262493848801,\n",
       " 0.022884713485836983,\n",
       " 0.00730504747480154,\n",
       " 0.05108628049492836,\n",
       " -0.028605662286281586,\n",
       " -0.017453044652938843,\n",
       " -0.053557224571704865,\n",
       " -0.0019779957365244627,\n",
       " -0.014511398039758205,\n",
       " -0.011208976618945599,\n",
       " 0.041824668645858765,\n",
       " 0.025760604068636894,\n",
       " 0.009081429801881313,\n",
       " 0.012275157496333122,\n",
       " 0.013874271884560585,\n",
       " -0.035534534603357315,\n",
       " -0.06564916670322418,\n",
       " -0.020060835406184196,\n",
       " 0.02263583429157734,\n",
       " 0.037518460303545,\n",
       " 0.02525267004966736,\n",
       " 0.00431250873953104,\n",
       " -0.020924905315041542,\n",
       " 0.07941845804452896,\n",
       " -0.014123785309493542,\n",
       " -0.010537290014326572,\n",
       " -0.1123788058757782,\n",
       " -0.029314273968338966,\n",
       " 0.08859329670667648,\n",
       " 0.012292257510125637,\n",
       " -0.012733916752040386,\n",
       " 0.02532954327762127,\n",
       " -0.05899713560938835,\n",
       " -0.10139857977628708,\n",
       " -0.015221645124256611,\n",
       " -0.061278682202100754,\n",
       " 0.020480012521147728,\n",
       " -0.060131121426820755,\n",
       " -0.012329736724495888,\n",
       " -0.021695278584957123,\n",
       " 0.05289805307984352,\n",
       " -0.007651684805750847,\n",
       " 0.021261168643832207,\n",
       " 0.06345474720001221,\n",
       " -0.058454543352127075,\n",
       " -0.005539469420909882,\n",
       " 0.08361567556858063,\n",
       " -0.010589602403342724,\n",
       " -0.041510917246341705,\n",
       " 0.044917404651641846,\n",
       " -0.00759165920317173,\n",
       " 0.029867617413401604,\n",
       " -0.02189793810248375,\n",
       " -0.08207610994577408,\n",
       " 0.025101615116000175,\n",
       " 0.042951799929142,\n",
       " 0.0063908942975103855,\n",
       " 0.004798149690032005,\n",
       " 0.017671210691332817,\n",
       " -0.0022825561463832855,\n",
       " 0.04465867206454277,\n",
       " -0.06338392943143845,\n",
       " 0.01926766149699688,\n",
       " 0.017956983298063278,\n",
       " 0.04724869132041931,\n",
       " 0.04366876929998398,\n",
       " -0.057938095182180405,\n",
       " -0.009309841319918633,\n",
       " 0.04690547287464142,\n",
       " 0.03630206733942032,\n",
       " 0.006143481936305761,\n",
       " 0.06523953378200531,\n",
       " -0.015181954018771648,\n",
       " 0.06797925382852554,\n",
       " -0.049565818160772324,\n",
       " 0.03457023948431015,\n",
       " -0.006686140317469835,\n",
       " -0.0008085585432127118,\n",
       " 0.04668916389346123,\n",
       " -0.01082219835370779,\n",
       " 0.016910316422581673,\n",
       " -0.017826803028583527,\n",
       " -0.055322784930467606,\n",
       " -0.049046147614717484,\n",
       " -0.02246953174471855,\n",
       " 0.024219708517193794,\n",
       " 0.063383087515831,\n",
       " 0.025232914835214615,\n",
       " -0.02147708646953106,\n",
       " 0.02535196579992771,\n",
       " -0.007573704235255718,\n",
       " 0.019834721460938454,\n",
       " 0.03316750377416611,\n",
       " 0.002692918758839369,\n",
       " 0.031077155843377113,\n",
       " 0.014228207059204578,\n",
       " 0.06641051918268204,\n",
       " -0.0647987574338913,\n",
       " -0.05045381560921669,\n",
       " 0.06150278076529503,\n",
       " -0.0507214218378067,\n",
       " -0.04298946633934975,\n",
       " -0.0238899365067482,\n",
       " -0.04456504434347153,\n",
       " -0.03406119346618652,\n",
       " 0.058177679777145386,\n",
       " -0.0011722262715920806,\n",
       " -0.023679649457335472,\n",
       " 0.03282207250595093,\n",
       " 0.012534690089523792,\n",
       " 0.008028569631278515,\n",
       " 0.015712598338723183,\n",
       " 0.03531219810247421,\n",
       " 0.04432743787765503,\n",
       " 0.014851571060717106,\n",
       " -0.0007326901541091502,\n",
       " -0.03445783257484436,\n",
       " 0.019656747579574585,\n",
       " -0.004553025588393211,\n",
       " 0.00816850271075964,\n",
       " 0.026792453601956367,\n",
       " -0.03753500059247017,\n",
       " -0.028981609269976616,\n",
       " -0.021177854388952255,\n",
       " -0.041438981890678406,\n",
       " 0.024378255009651184,\n",
       " -0.03516298532485962,\n",
       " 0.03420906141400337,\n",
       " -0.015996715053915977,\n",
       " -0.016656897962093353,\n",
       " -0.039746299386024475,\n",
       " -0.0006544048083014786,\n",
       " -0.07985402643680573,\n",
       " 0.019655341282486916,\n",
       " 0.03171144798398018,\n",
       " 0.0028599267825484276,\n",
       " -0.01638939045369625,\n",
       " 0.05141962692141533,\n",
       " -0.02344757504761219,\n",
       " -0.008861400187015533,\n",
       " 0.038233984261751175,\n",
       " -0.02776852436363697,\n",
       " -0.028537889942526817,\n",
       " -0.06147114560008049,\n",
       " -0.008505829609930515,\n",
       " -0.03510836511850357,\n",
       " -0.005436816718429327,\n",
       " 0.01580243930220604,\n",
       " 0.018280286341905594,\n",
       " -0.0021098533179610968,\n",
       " -0.04721468314528465,\n",
       " -0.016302188858389854,\n",
       " 0.06559819728136063,\n",
       " 0.015495628118515015,\n",
       " -0.005178459919989109,\n",
       " 0.02342359535396099,\n",
       " 0.013659382238984108,\n",
       " 0.06907043606042862,\n",
       " -0.028205756098031998,\n",
       " -0.05322875827550888,\n",
       " 0.029919736087322235,\n",
       " 0.007609053980559111,\n",
       " 0.03240805119276047,\n",
       " -0.027457084506750107,\n",
       " -0.005093097686767578,\n",
       " 0.0244493056088686,\n",
       " -0.02984626218676567,\n",
       " 0.044904839247465134,\n",
       " 0.04032481834292412,\n",
       " 0.04276043176651001,\n",
       " -0.038556504994630814,\n",
       " -0.032572679221630096,\n",
       " 0.0185190849006176,\n",
       " -0.028770774602890015,\n",
       " -0.002551078563556075,\n",
       " 0.0012870163191109896,\n",
       " 0.048368342220783234,\n",
       " -0.020888062193989754,\n",
       " -0.022163202986121178,\n",
       " 0.0162665992975235,\n",
       " -0.026787037029862404,\n",
       " -0.04376942664384842,\n",
       " 0.06887894868850708,\n",
       " 0.03444064408540726,\n",
       " -0.004916480742394924,\n",
       " 0.05571210756897926,\n",
       " 0.015132065862417221,\n",
       " -0.0012755675707012415,\n",
       " 0.04395173862576485,\n",
       " 0.019792942330241203,\n",
       " 0.02508924901485443,\n",
       " -0.03136010468006134,\n",
       " -0.011586342006921768,\n",
       " 0.03092801198363304,\n",
       " 0.044979702681303024,\n",
       " -0.06679543852806091,\n",
       " -0.026936454698443413,\n",
       " -0.024433590471744537,\n",
       " 0.034208983182907104,\n",
       " 0.01629059761762619,\n",
       " 0.02529524266719818,\n",
       " 0.005183934699743986,\n",
       " -0.035847265273332596,\n",
       " 0.011761268600821495,\n",
       " 0.027297401800751686,\n",
       " -0.08346753567457199,\n",
       " 0.00913651380687952,\n",
       " -0.06733430176973343,\n",
       " 0.0224755946546793,\n",
       " -0.03347492963075638,\n",
       " 0.011621546000242233,\n",
       " 0.061354249715805054,\n",
       " -0.0027572938706725836,\n",
       " 0.0035316874273121357,\n",
       " -0.02244546078145504,\n",
       " -0.0026383085642009974,\n",
       " -0.041713882237672806,\n",
       " 0.000820510380435735,\n",
       " -0.06817469000816345,\n",
       " -0.006890734191983938,\n",
       " -0.0072839693166315556,\n",
       " 0.008241517469286919,\n",
       " -0.04240100458264351,\n",
       " 0.03534863144159317,\n",
       " 0.01226557232439518,\n",
       " 0.003391561796888709,\n",
       " 0.005554760806262493,\n",
       " -0.03862575814127922,\n",
       " 0.07163363695144653,\n",
       " 0.043758049607276917,\n",
       " -0.034504227340221405,\n",
       " 0.024233631789684296,\n",
       " -0.013378741219639778,\n",
       " 0.011471863836050034,\n",
       " -0.01268206536769867,\n",
       " 0.009211369790136814,\n",
       " 0.0029338968452066183,\n",
       " -0.07062236964702606,\n",
       " 0.0017355192685499787,\n",
       " 0.000776102882809937,\n",
       " -0.05332057178020477,\n",
       " -0.015711026266217232,\n",
       " -0.07306735217571259,\n",
       " 0.029659925028681755,\n",
       " -0.014840134419500828,\n",
       " -0.03769133612513542,\n",
       " -0.008135727606713772,\n",
       " -0.028121313080191612,\n",
       " 0.019938793033361435,\n",
       " 0.04303430765867233,\n",
       " -0.019125504419207573,\n",
       " -0.04379427805542946,\n",
       " -0.030233783647418022,\n",
       " 0.034205105155706406,\n",
       " -0.1289433389902115,\n",
       " 0.01876971684396267,\n",
       " -0.0013636015355587006,\n",
       " -0.03365596383810043,\n",
       " -0.06970860809087753,\n",
       " 0.014286465011537075,\n",
       " 0.04033824801445007,\n",
       " 0.006457101553678513,\n",
       " 0.014318997971713543,\n",
       " -0.04051735997200012,\n",
       " -0.0003344920405652374,\n",
       " -0.01996772177517414,\n",
       " 0.04891873151063919,\n",
       " -0.027563296258449554,\n",
       " 0.029296455904841423,\n",
       " 0.004969187546521425,\n",
       " 0.04152185842394829,\n",
       " -0.00043216452468186617,\n",
       " 0.09334666281938553,\n",
       " 0.036642059683799744,\n",
       " -0.012005027383565903,\n",
       " -0.00553768128156662,\n",
       " 0.052756402641534805,\n",
       " 0.006837915629148483,\n",
       " 0.04798424243927002,\n",
       " -0.008525914512574673,\n",
       " -0.009076064452528954,\n",
       " -0.029326321557164192,\n",
       " 0.04218412563204765,\n",
       " -0.008596240542829037,\n",
       " 0.005607778672128916,\n",
       " -0.0028088639955967665,\n",
       " 0.06995856016874313,\n",
       " -0.0537680983543396,\n",
       " 0.004311331547796726,\n",
       " -0.058149755001068115,\n",
       " 0.000389850843930617,\n",
       " 0.023682137951254845,\n",
       " 0.01962324045598507,\n",
       " -0.04290573671460152,\n",
       " -0.014893067069351673,\n",
       " -0.014941687695682049,\n",
       " -0.0067320154048502445,\n",
       " -0.032331038266420364,\n",
       " 0.030028751119971275,\n",
       " 0.07784581929445267,\n",
       " 0.02652718685567379,\n",
       " 0.018818149343132973,\n",
       " 0.10079953819513321,\n",
       " -0.026828590780496597,\n",
       " 0.024715932086110115,\n",
       " -0.029291167855262756,\n",
       " -0.0257499348372221,\n",
       " 0.03351414576172829,\n",
       " -0.04802548512816429,\n",
       " -0.01329866610467434,\n",
       " -0.07085320353507996,\n",
       " 0.03516921401023865,\n",
       " -0.006450216751545668,\n",
       " 0.0014187981141731143,\n",
       " -0.03799407184123993,\n",
       " 0.01227609533816576,\n",
       " -0.028900912031531334,\n",
       " -0.03452681750059128,\n",
       " 0.018151473253965378,\n",
       " -0.003676022868603468,\n",
       " 0.020299896597862244,\n",
       " 0.0392385832965374,\n",
       " 0.005216616205871105,\n",
       " 0.048728588968515396,\n",
       " -0.04314390942454338,\n",
       " 0.026975831016898155,\n",
       " -0.005708605516701937,\n",
       " -0.07795558124780655,\n",
       " -0.0187778789550066,\n",
       " 1.950235673575662e-05,\n",
       " -0.004165430553257465,\n",
       " -0.013337717391550541,\n",
       " 0.014994919300079346,\n",
       " 0.053073979914188385,\n",
       " 0.004304846748709679,\n",
       " 0.04841817170381546,\n",
       " -0.014102564193308353,\n",
       " 0.035504765808582306,\n",
       " 0.02638196386396885,\n",
       " -0.025956710800528526,\n",
       " 0.04423744976520538,\n",
       " -0.045661844313144684,\n",
       " 0.04828353971242905,\n",
       " 0.09447771310806274,\n",
       " 0.002758328104391694,\n",
       " 0.0005283771897666156,\n",
       " 4.256759712006897e-05,\n",
       " -0.0014979940606281161,\n",
       " -0.029275955632328987,\n",
       " 0.015680665150284767,\n",
       " 0.03848559409379959,\n",
       " -0.02984701283276081,\n",
       " -0.07123138010501862,\n",
       " -0.023076724261045456,\n",
       " 0.008956209756433964,\n",
       " -0.03883236646652222,\n",
       " 0.020806824788451195,\n",
       " 0.019965006038546562,\n",
       " 0.0006292115431278944,\n",
       " -0.058523792773485184,\n",
       " -0.015092895366251469,\n",
       " -0.004864772316068411,\n",
       " 0.0014309972757473588,\n",
       " 0.03782801330089569,\n",
       " -0.05877868831157684,\n",
       " -0.027365364134311676,\n",
       " -0.006414605304598808,\n",
       " 0.0491112656891346,\n",
       " -0.027450881898403168,\n",
       " 0.003931869752705097,\n",
       " 0.06556558609008789,\n",
       " -0.017787188291549683,\n",
       " -0.012314928695559502,\n",
       " -0.0015258303610607982,\n",
       " 0.011145291849970818,\n",
       " -0.10509050637483597,\n",
       " -0.02543022483587265,\n",
       " -0.02107500657439232,\n",
       " 0.008154875598847866,\n",
       " 0.005032115615904331,\n",
       " 0.011258517391979694,\n",
       " 0.03538285568356514,\n",
       " 0.01005258783698082,\n",
       " -0.02753416821360588,\n",
       " -0.0275872852653265,\n",
       " -0.031412411481142044,\n",
       " -0.04526940733194351,\n",
       " -0.006516605149954557,\n",
       " 0.04387758672237396,\n",
       " -0.01503799855709076,\n",
       " -0.0034435198176652193,\n",
       " 0.001502100727520883,\n",
       " -0.04514551907777786,\n",
       " 0.01709992066025734,\n",
       " -0.009576825425028801,\n",
       " -0.059541329741477966,\n",
       " 0.003414981998503208,\n",
       " -0.017904480919241905,\n",
       " -0.015371226705610752,\n",
       " 0.0122518977150321,\n",
       " -0.09305690973997116,\n",
       " 0.053666893392801285,\n",
       " -0.03854849562048912,\n",
       " -0.014944760128855705,\n",
       " -0.06368932127952576,\n",
       " -0.061611343175172806,\n",
       " -0.03798167407512665,\n",
       " 0.004969462286680937,\n",
       " 0.057093385607004166,\n",
       " 0.003134549828246236,\n",
       " 0.038014043122529984,\n",
       " -0.009885297156870365,\n",
       " 0.0037534444127231836,\n",
       " 0.005950384773313999,\n",
       " -0.08633586764335632,\n",
       " 0.07060351222753525,\n",
       " -0.010871749371290207,\n",
       " 0.001360249938443303,\n",
       " -0.000932549184653908,\n",
       " 0.044308342039585114,\n",
       " 0.004969185218214989,\n",
       " 0.030611323192715645,\n",
       " -0.036352112889289856,\n",
       " 0.007462348323315382,\n",
       " -0.013102377764880657,\n",
       " -0.01578649878501892,\n",
       " -0.01685439422726631,\n",
       " -0.05277470871806145,\n",
       " 0.057428471744060516,\n",
       " -0.051023390144109726,\n",
       " -0.011904396116733551,\n",
       " -0.001122657093219459,\n",
       " 0.04877053573727608,\n",
       " 0.01647622138261795,\n",
       " 0.02260962873697281,\n",
       " -0.023815615102648735,\n",
       " 0.013805841095745564,\n",
       " -0.015029863454401493,\n",
       " -0.02843320369720459,\n",
       " -0.021197745576500893,\n",
       " 0.025649957358837128,\n",
       " 0.015234986320137978,\n",
       " 0.012330842204391956,\n",
       " 0.011164337396621704,\n",
       " -0.006110581569373608,\n",
       " -0.019602295011281967,\n",
       " -0.008211949840188026,\n",
       " -0.01560433954000473,\n",
       " 0.009505245834589005,\n",
       " 0.06100188568234444,\n",
       " 0.007874694652855396,\n",
       " -0.023110682144761086,\n",
       " -0.04175825044512749,\n",
       " -0.01541556604206562,\n",
       " -0.030391953885555267,\n",
       " 0.051670048385858536,\n",
       " -0.07907964289188385,\n",
       " -0.004185286350548267,\n",
       " 0.008970340713858604,\n",
       " 0.0021294238977134228,\n",
       " -0.01903717964887619,\n",
       " 0.006184273865073919,\n",
       " 0.02990245819091797,\n",
       " -0.00953903328627348,\n",
       " 0.005551429931074381,\n",
       " 0.05387149006128311,\n",
       " -0.02918492630124092,\n",
       " -0.0021841435227543116,\n",
       " 0.020101606845855713,\n",
       " 0.013337627053260803,\n",
       " -0.029612770304083824,\n",
       " 0.019683172926306725,\n",
       " -0.012386214919388294,\n",
       " -0.10165007412433624,\n",
       " -0.01591097190976143,\n",
       " -0.0046632722951471806,\n",
       " -0.024644479155540466,\n",
       " 0.012407693080604076,\n",
       " 0.022170621901750565,\n",
       " -0.025813261047005653,\n",
       " 0.00283280061557889,\n",
       " -0.03137308731675148,\n",
       " 0.03225836530327797,\n",
       " -0.05315868929028511,\n",
       " -0.020993385463953018,\n",
       " 0.02195299230515957,\n",
       " 0.002126778243109584,\n",
       " 0.01938035525381565,\n",
       " 0.037054967135190964,\n",
       " -0.00788912083953619,\n",
       " -0.028908241540193558,\n",
       " 0.007666975725442171,\n",
       " 0.020003166049718857,\n",
       " 0.0352477952837944,\n",
       " 0.022812185809016228,\n",
       " -0.05451691895723343,\n",
       " 0.031221361830830574,\n",
       " -0.0007930244319140911,\n",
       " -0.08200615644454956,\n",
       " -0.005941678769886494,\n",
       " 0.02058999426662922,\n",
       " -0.010571344755589962,\n",
       " 0.02345462702214718,\n",
       " 0.042556583881378174,\n",
       " -0.030278334394097328,\n",
       " -0.012028409168124199,\n",
       " -0.010323988273739815,\n",
       " -0.025506870821118355,\n",
       " 0.01866868883371353,\n",
       " 0.0222312081605196,\n",
       " -0.028371015563607216,\n",
       " -0.025387339293956757,\n",
       " 0.0057513536885380745,\n",
       " 0.0028657009825110435,\n",
       " 0.01843712292611599,\n",
       " 0.07363656908273697,\n",
       " 0.02003856748342514,\n",
       " -0.015456043183803558,\n",
       " -0.0349089615046978,\n",
       " 0.07125309854745865,\n",
       " -0.025992022827267647,\n",
       " -0.02260083146393299,\n",
       " 0.025013282895088196,\n",
       " 0.015133319422602654,\n",
       " 0.026542777195572853,\n",
       " 0.03284652531147003,\n",
       " -0.022201092913746834,\n",
       " -0.028367234393954277,\n",
       " -0.03241298720240593,\n",
       " -0.010089460760354996,\n",
       " -0.04076505824923515,\n",
       " 0.034772325307130814,\n",
       " -0.019455863162875175,\n",
       " 0.025945648550987244,\n",
       " 0.056812748312950134,\n",
       " -0.008616465143859386,\n",
       " 0.0256196241825819,\n",
       " 0.06304553151130676,\n",
       " 0.092257060110569,\n",
       " 0.032001301646232605,\n",
       " 0.0718841478228569,\n",
       " -0.06249533221125603,\n",
       " 0.02461327612400055,\n",
       " -0.03658665344119072,\n",
       " 0.00786793977022171,\n",
       " 0.023723134770989418,\n",
       " 0.001416364568285644,\n",
       " 0.016731565818190575,\n",
       " 0.00430148234590888,\n",
       " -0.01578620821237564,\n",
       " -0.004023867659270763,\n",
       " 0.008942751213908195,\n",
       " -0.000345551292411983,\n",
       " -0.010754629969596863,\n",
       " -0.024623828008770943,\n",
       " 0.033996716141700745,\n",
       " 0.039200302213430405,\n",
       " -0.0076505509205162525,\n",
       " -0.00131194107234478,\n",
       " -0.01666194386780262,\n",
       " 0.07930213212966919,\n",
       " -0.013898390345275402,\n",
       " -0.0689609944820404,\n",
       " 0.012000112794339657,\n",
       " -0.009581432677805424,\n",
       " -0.04837122559547424,\n",
       " -0.031414881348609924,\n",
       " 0.07315132766962051,\n",
       " -0.039088670164346695,\n",
       " 0.00218871864490211,\n",
       " -0.05896149203181267,\n",
       " -0.01683167926967144,\n",
       " 0.002672727219760418,\n",
       " 0.016292845830321312,\n",
       " -0.009785396046936512,\n",
       " 0.024775490164756775,\n",
       " 0.02171732671558857,\n",
       " -0.000452090724138543,\n",
       " -0.01781918667256832,\n",
       " 0.07011551409959793,\n",
       " 0.009600261226296425,\n",
       " 0.04886496439576149,\n",
       " 0.054319556802511215,\n",
       " -0.010140292346477509,\n",
       " 0.04589186981320381,\n",
       " -0.04373558610677719,\n",
       " -0.028303582221269608,\n",
       " -0.024007361382246017,\n",
       " 0.010826018638908863,\n",
       " -0.0011123847216367722,\n",
       " -0.014379525557160378,\n",
       " -0.07625262439250946,\n",
       " -0.014142941683530807,\n",
       " -0.008852525614202023,\n",
       " -0.020374955609440804,\n",
       " -0.001709308591671288,\n",
       " 0.10109556466341019,\n",
       " 0.031229877844452858,\n",
       " -0.09570297598838806,\n",
       " -0.07875523716211319,\n",
       " -0.017420509830117226,\n",
       " -0.028816895559430122,\n",
       " 0.005566686391830444,\n",
       " 0.006137389224022627,\n",
       " -0.04127610847353935,\n",
       " -0.004854386672377586,\n",
       " -0.010346938855946064,\n",
       " -0.05168088898062706,\n",
       " -0.06504295021295547,\n",
       " 0.01440028753131628,\n",
       " -0.021751906722784042,\n",
       " -0.01853206381201744,\n",
       " 0.00021054380340501666,\n",
       " 0.013655711896717548,\n",
       " 0.02776460349559784,\n",
       " -0.020192818716168404,\n",
       " -0.014793135225772858,\n",
       " -0.027256937697529793,\n",
       " -0.07850465923547745,\n",
       " -0.022812915965914726,\n",
       " 0.08268923312425613,\n",
       " -0.03677649796009064,\n",
       " 0.019542738795280457,\n",
       " 0.03568365424871445,\n",
       " 0.00893871858716011,\n",
       " 0.06488438695669174,\n",
       " 0.03394994139671326,\n",
       " -0.005225707311183214,\n",
       " -0.007535950746387243,\n",
       " 0.04079103097319603,\n",
       " -0.012039696797728539,\n",
       " 0.02492239885032177,\n",
       " -0.009239216335117817,\n",
       " -0.015043286606669426,\n",
       " 0.006247411482036114,\n",
       " 0.005025108810514212,\n",
       " 0.018266187980771065,\n",
       " -0.003696901025250554,\n",
       " 0.009617170318961143,\n",
       " -0.042930785566568375,\n",
       " -0.049952298402786255,\n",
       " 0.028880316764116287,\n",
       " -0.03642009571194649,\n",
       " -0.03257705643773079,\n",
       " 0.04520998150110245,\n",
       " 0.0666457861661911,\n",
       " 0.01486800517886877,\n",
       " 0.028859734535217285,\n",
       " -0.012797576375305653,\n",
       " -0.01074227038770914,\n",
       " -0.002966837724670768,\n",
       " -0.0064021628350019455,\n",
       " -0.04354814067482948,\n",
       " -0.025676313787698746,\n",
       " -0.004429238382726908,\n",
       " 0.012866475619375706,\n",
       " -0.004868005868047476,\n",
       " 0.03388295695185661,\n",
       " 0.040393806993961334,\n",
       " 0.03633559122681618,\n",
       " 0.058341916650533676,\n",
       " 0.0310994703322649,\n",
       " -0.035197045654058456,\n",
       " -0.04798571765422821,\n",
       " 0.04923807084560394,\n",
       " 0.010059311985969543,\n",
       " -0.042198099195957184,\n",
       " 0.01152036152780056,\n",
       " 0.03925744816660881,\n",
       " -0.039043281227350235,\n",
       " 0.06095916032791138,\n",
       " 0.07288889586925507,\n",
       " 0.03350241482257843,\n",
       " 0.04895680770277977,\n",
       " -0.014692160300910473,\n",
       " -0.07295378297567368,\n",
       " 0.06140528619289398,\n",
       " -0.05079076066613197,\n",
       " -0.007999186404049397,\n",
       " -0.021944930776953697,\n",
       " 0.0023146383464336395,\n",
       " 0.0908806100487709,\n",
       " 0.007524020504206419,\n",
       " -0.008521058596670628,\n",
       " 0.022028647363185883,\n",
       " 0.0010133610339835286,\n",
       " 0.09751821309328079,\n",
       " 0.03371819853782654,\n",
       " 0.023555153980851173,\n",
       " 0.021802114322781563,\n",
       " -0.07597586512565613,\n",
       " -0.014945506118237972,\n",
       " 0.007436845451593399,\n",
       " 0.024674469605088234,\n",
       " 0.014347013086080551,\n",
       " 0.03192635998129845,\n",
       " -0.002852905308827758,\n",
       " -0.015654677525162697,\n",
       " -0.019085343927145004,\n",
       " 0.027190642431378365,\n",
       " -0.11129061877727509,\n",
       " -0.003835484152659774,\n",
       " 0.008857332170009613,\n",
       " -0.04270448163151741,\n",
       " -0.005413864739239216,\n",
       " 0.02110816165804863,\n",
       " 0.024410296231508255,\n",
       " -0.006140475627034903,\n",
       " -0.007799160201102495,\n",
       " -0.0008874840568751097,\n",
       " 0.00559002161026001,\n",
       " -0.03402452915906906,\n",
       " -0.03366005793213844,\n",
       " 0.029389305040240288,\n",
       " -0.03259098529815674,\n",
       " -0.0059355380944907665,\n",
       " 0.018408332020044327,\n",
       " 0.03334110230207443,\n",
       " -0.004785189405083656]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emdedding_model.embed_query(\"where is new delhi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bd14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Data Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de9ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2001811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(),\"data\",\"sample.pdf\")\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "977ea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100,length_function=len)\n",
    "\n",
    "data_splits = text_spliter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f08225",
   "metadata": {},
   "source": [
    "#FAISS is in memory storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c9db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vector_store = FAISS.from_documents(data_splits, emdedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "403b4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = vector_store.similarity_search(\"llam2 finetunning bencmark experiments?\")\n",
    "retriver = vector_store.as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef8814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning Representations, 2022.\\n44'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de515fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final learning rate down to 10% of the peak learning rate. We use a weight decay of0.1 and gradient clipping\\nof 1.0. Figure 5 (a) shows the training loss forLlama 2with these hyperparameters.\\n5'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c07d0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "597c4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "prompt = PromptTemplate(template=prompt_template,input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "935d10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b4695fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "        {\"context\": retriver | format_docs, \"question\": RunnablePassthrough()}\n",
    "         |prompt\n",
    "         |model\n",
    "         |StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8f88549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s try to figure out what the user is asking here. They want to know about the Llama2 fine-tuning benchmark experiments based on the provided context. \\n\\nFirst, I\\'ll look through the context to see where finetuning is mentioned. The context includes various numbers and tables comparing different models, including Llama 2 at different sizes (7B, 13B, 34B, 70B) and other models like ChatGPT, MPT-instruct, Falcon-instruct. There are several sections with benchmark results, like MMLU, HellaSwag, Winogrande, etc. \\n\\nLooking at the first part, there\\'s a mention of \"Fine-tuned\" under Llama 2 with different metrics. The numbers seem to represent performance metrics across different benchmarks. For example, under \"Fine-tuned\" there are entries like ChatGPT with very low numbers compared to Llama 2\\'s 7B, 13B, etc. Then there\\'s a section about training hyperparameters: final learning rate down to 10% of peak, weight decay of 0.1, gradient clipping of 1.0.\\n\\nFurther down, there\\'s a section titled \"Llama 2-Chat\" with different model sizes and their performance. Also, a table (Table 20) showing performance on standard benchmarks like Human-Eval and MBPP with pass@1, pass@100, etc. \\n\\nThe user is asking specifically about the fine-tuning benchmarks. The context does mention that fine-tuning, annotation, and evaluation were done on third-party cloud compute. Also, there\\'s a line about the training factors using custom libraries and Meta\\'s clusters. \\n\\nThe numbers in the tables under \"Fine-tuned\" might represent the results of these experiments. For example, the Llama 2-Chat models have higher numbers compared to base models. The Human-Eval and MBPP results show how the fine-tuned models perform on coding tasks. \\n\\nHowever, the context doesn\\'t give detailed descriptions of the experimental setup beyond hyperparameters like learning rate, weight decay, and gradient clipping. There\\'s no explicit mention of the specific benchmarks used for fine-tuning beyond the listed results. The user might be looking for information on the benchmarks, the methodology, or the results. Since the context does provide some results but lacks detailed methodology, I need to check if it\\'s enough.\\n\\nThe answer should mention the hyperparameters used during fine-tuning, the models compared (like Llama 2-Chat vs base, other models), and the benchmarks where they were tested (MMLU, HellaSwag, etc.), as well as specific performance metrics like pass@1. Since the context does have this information, even if it\\'s in a condensed table form, it\\'s sufficient to answer the question without saying there\\'s not enough info.\\n</think>\\n\\nThe Llama 2 fine-tuning benchmark experiments evaluated the performance of fine-tuned models across various tasks and benchmarks. Key details include:  \\n\\n1. **Hyperparameters**: Training used a final learning rate reduced to 10% of the peak, weight decay of 0.1, and gradient clipping of 1.0.  \\n2. **Models Compared**: Llama 2 base models (7B, 13B, 34B, 70B), fine-tuned variants (e.g., Llama 2-Chat), and competitors like ChatGPT, MPT-instruct, and Falcon-instruct.  \\n3. **Benchmarks**: Results were reported on academic benchmarks (e.g., MMLU, HellaSwag, Winogrande) and coding tasks (Human-Eval, MBPP). For example:  \\n   - On **Human-Eval**, Llama 2 70B achieved 45.0% pass@1 accuracy, outperforming smaller variants and competitors like Falcon 40B (29.8%).  \\n   - On **MMLU (5-shot)**, Llama 2 70B scored 71.9%, exceeding Llama 1 65B (70.7%).  \\n4. **Performance Trends**: Larger models generally showed better results. For instance, Llama 2-Chat 70B achieved 89.0% pass@1 on MBPP, a significant improvement over its base counterpart (77.2% for 34B).  \\n\\nThese experiments highlight the effectiveness of fine-tuning in enhancing task-specific performance, with Llama 2-Chat variants demonstrating strong results relative to both earlier Llama versions and other open-source models.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
